# üìã T√†i li·ªáu k·ªπ thu·∫≠t - Gym Exercise Form Evaluation System

## üéØ T·ªïng quan h·ªá th·ªëng

H·ªá th·ªëng ƒë√°nh gi√° t∆∞ th·∫ø t·∫≠p luy·ªán th·ªÉ d·ª•c l√† m·ªôt ·ª©ng d·ª•ng AI th·ªùi gian th·ª±c, k·∫øt h·ª£p gi·ªØa computer vision v√† deep learning ƒë·ªÉ ph√¢n t√≠ch v√† ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng ƒë·ªông t√°c c·ªßa ng∆∞·ªùi t·∫≠p.

### üîÑ Lu·ªìng x·ª≠ l√Ω ch√≠nh

1. **Thu th·∫≠p d·ªØ li·ªáu ƒë·∫ßu v√†o**
   - Camera ho·∫∑c video stream
   - Frame rate: 30 FPS
   - ƒê·ªô ph√¢n gi·∫£i: 640x480

2. **X·ª≠ l√Ω h√¨nh ·∫£nh**
   - Chuy·ªÉn ƒë·ªïi sang RGB
   - Resize v√† chu·∫©n h√≥a
   - √Åp d·ª•ng MediaPipe Pose

3. **Ph√¢n t√≠ch t∆∞ th·∫ø**
   - Tr√≠ch xu·∫•t 33 ƒëi·ªÉm m·ªëc (landmarks)
   - T√≠nh to√°n g√≥c kh·ªõp
   - Chu·∫©n h√≥a d·ªØ li·ªáu

4. **ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng**
   - M√¥ h√¨nh LSTM ph√¢n t√≠ch chu·ªói ƒë·ªông t√°c
   - T√≠nh ƒëi·ªÉm ch·∫•t l∆∞·ª£ng (0-1)
   - Ph√¢n lo·∫°i tr·∫°ng th√°i

5. **Hi·ªÉn th·ªã k·∫øt qu·∫£**
   - V·∫Ω skeleton
   - Hi·ªÉn th·ªã g√≥c kh·ªõp
   - C·∫≠p nh·∫≠t UI realtime

## üß† Ki·∫øn tr√∫c AI

### 1. Pose Detection (MediaPipe)

```python
# C·∫•u h√¨nh MediaPipe
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
)
```

- **Input**: Frame RGB
- **Output**: 33 landmarks (x, y, z, visibility)
- **T·ªëc ƒë·ªô**: ~30ms/frame

### 2. LSTM Model

```python
class PoseLSTM(nn.Module):
    def __init__(self):
        super().__init__()
        self.lstm = nn.LSTM(
            input_size=132,  # 33 landmarks * 4 features
            hidden_size=128,
            num_layers=1,
            batch_first=True
        )
        self.fc = nn.Sequential(
            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )
```

#### Th√¥ng s·ªë m√¥ h√¨nh
- **Input size**: 132 features
  - 33 landmarks √ó 4 features (x, y, z, visibility)
- **Hidden size**: 128 units
- **Output size**: 1 (ƒëi·ªÉm ch·∫•t l∆∞·ª£ng)
- **Dropout rate**: 0.5
- **Batch size**: 32
- **Learning rate**: 0.001

### 3. Feature Engineering

#### Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng
1. **Landmark coordinates**
   - Normalize t·ªça ƒë·ªô (0-1)
   - T√≠nh relative positions

2. **Joint angles**
   - Elbow angles (left/right)
   - Knee angles (left/right)
   - Hip angles
   - Shoulder angles

3. **Movement features**
   - Velocity
   - Acceleration
   - Range of motion

## üìä ƒê√°nh gi√° hi·ªáu nƒÉng

### 1. Accuracy Metrics
- **Training accuracy**: 98%
- **Validation accuracy**: 95%
- **Test accuracy**: 94%

### 2. Performance Metrics
- **FPS**: 20-30
- **Latency**: <50ms
- **Memory usage**: ~500MB
- **CPU usage**: 30-40%

### 3. Robustness
- **Lighting conditions**: Ho·∫°t ƒë·ªông t·ªët trong ƒëi·ªÅu ki·ªán √°nh s√°ng v·ª´a ph·∫£i
- **Camera distance**: 1-3m
- **View angle**: 0-45 ƒë·ªô
- **Clothing**: T·ªëi thi·ªÉu che khu·∫•t kh·ªõp

## üîß T·ªëi ∆∞u h√≥a

### 1. Performance Optimization
- **Frame skipping**: B·ªè qua frame khi FPS < 20
- **Batch processing**: X·ª≠ l√Ω 32 frames/batch
- **Model quantization**: FP16
- **OpenMP parallelization**

### 2. Memory Management
- **Frame buffer**: 32 frames
- **Tensor recycling**
- **Garbage collection**

### 3. UI Optimization
- **Double buffering**
- **Lazy rendering**
- **Event-driven updates**

## üõ°Ô∏è X·ª≠ l√Ω l·ªói

### 1. Input Validation
```python
def validate_landmarks(landmarks):
    if not landmarks or len(landmarks) != 33:
        return False
    return all(0 <= l.x <= 1 and 0 <= l.y <= 1 for l in landmarks)
```

### 2. Error Recovery
- **Pose detection failure**: S·ª≠ d·ª•ng frame tr∆∞·ªõc
- **Model inference error**: Reset model state
- **UI freeze**: Restart display thread

### 3. Logging
- **Error logs**: `error.log`
- **Performance logs**: `performance.log`
- **Debug logs**: `debug.log`

## üîÑ Quy tr√¨nh hu·∫•n luy·ªán

### 1. Data Collection
- **Dataset size**: 10,000 samples
- **Split ratio**: 70/15/15
- **Augmentation**:
  - Rotation (¬±15¬∞)
  - Scaling (¬±10%)
  - Mirroring

### 2. Training Process
```python
# Training loop
for epoch in range(epochs):
    model.train()
    for batch in train_loader:
        optimizer.zero_grad()
        output = model(batch)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
```

### 3. Validation
- **Early stopping**: patience=10
- **Learning rate decay**: factor=0.1
- **Model checkpointing**

## üìà Roadmap

### Phase 1: Core Features
- [x] Pose detection
- [x] Basic evaluation
- [x] Simple UI

### Phase 2: Enhancement
- [ ] Multi-person support
- [ ] Exercise recognition
- [ ] Custom exercise library

### Phase 3: Advanced Features
- [ ] Real-time coaching
- [ ] Progress tracking
- [ ] Social features

## üîç Troubleshooting

### Common Issues
1. **Low FPS**
   - Check CPU usage
   - Reduce frame resolution
   - Enable frame skipping

2. **Inaccurate Detection**
   - Adjust lighting
   - Check camera position
   - Update MediaPipe

3. **UI Lag**
   - Clear frame buffer
   - Reduce update frequency
   - Check memory usage

### Solutions
```python
# Performance monitoring
def monitor_performance():
    fps = calculate_fps()
    if fps < 20:
        enable_frame_skipping()
        reduce_resolution()
```

---

<div align="center">
*Last updated: March 2024*
</div> 